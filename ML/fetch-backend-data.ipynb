{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f1913e6-6011-4816-b906-28f5b390830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travels DataFrame:\n",
      "   id            name                                            country  \\\n",
      "0   2   Shelby Daniel  Consectetur qui laboriosam dolore fugiat quaer...   \n",
      "1   3   Jasper Howard  Quaerat sed cupidatat ipsum qui et repellendus...   \n",
      "2   4  Abra Macdonald  Est repellendus Excepteur iure architecto eu p...   \n",
      "3   5     Winter Bush  Eaque quas veniam ea deleniti non in dolores v...   \n",
      "4   7     Lana Conner  Sequi iure quis tempor sunt recusandae Nulla a...   \n",
      "\n",
      "                                                city  \\\n",
      "0  Voluptatem quo aut dolor dolorem excepturi mag...   \n",
      "1  Necessitatibus eligendi minim quibusdam aut ut...   \n",
      "2  Adipisci rerum inventore similique voluptatum ...   \n",
      "3  Illum duis corporis magna sit aut aute in blan...   \n",
      "4                 Quasi at sint ullamco perspiciatis   \n",
      "\n",
      "                                         description  user_id  \n",
      "0  Fugit beatae voluptate cupidatat unde sed cum ...        2  \n",
      "1  Ut id odio cupiditate illo voluptate deleniti ...        2  \n",
      "2  Nihil officiis proident qui quis laboris quia ...        3  \n",
      "3  In dolor voluptate cumque omnis delectus eos e...        3  \n",
      "4  Voluptatem ad rerum assumenda amet pariatur Si...        6  \n",
      "\n",
      "Checklists DataFrame:\n",
      "   id             name                                        description  \\\n",
      "0   1  Ashely Cantrell  Vero irure fugiat est fugit laudantium iste ve...   \n",
      "1   2   Lucian Ferrell  Beatae tempor eiusmod saepe excepturi sint opt...   \n",
      "2   3      Dale Ramsey  Fugit sint sapiente molestiae atque autem repr...   \n",
      "3   5  Charissa Graham  Et quis lorem temporibus reprehenderit est sun...   \n",
      "4   6    Scott Schultz  Quibusdam omnis fuga Ut quod mollitia anim in ...   \n",
      "\n",
      "   user_id  \n",
      "0        2  \n",
      "1        3  \n",
      "2        3  \n",
      "3        6  \n",
      "4        6  \n",
      "\n",
      "Merged DataFrame:\n",
      "   id          name_x                                            country  \\\n",
      "0   2   Shelby Daniel  Consectetur qui laboriosam dolore fugiat quaer...   \n",
      "1   3   Jasper Howard  Quaerat sed cupidatat ipsum qui et repellendus...   \n",
      "2   4  Abra Macdonald  Est repellendus Excepteur iure architecto eu p...   \n",
      "3   5     Winter Bush  Eaque quas veniam ea deleniti non in dolores v...   \n",
      "4   7     Lana Conner  Sequi iure quis tempor sunt recusandae Nulla a...   \n",
      "\n",
      "                                                city  \\\n",
      "0  Voluptatem quo aut dolor dolorem excepturi mag...   \n",
      "1  Necessitatibus eligendi minim quibusdam aut ut...   \n",
      "2  Adipisci rerum inventore similique voluptatum ...   \n",
      "3  Illum duis corporis magna sit aut aute in blan...   \n",
      "4                 Quasi at sint ullamco perspiciatis   \n",
      "\n",
      "                                       description_x  user_id_x  \\\n",
      "0  Fugit beatae voluptate cupidatat unde sed cum ...          2   \n",
      "1  Ut id odio cupiditate illo voluptate deleniti ...          2   \n",
      "2  Nihil officiis proident qui quis laboris quia ...          3   \n",
      "3  In dolor voluptate cumque omnis delectus eos e...          3   \n",
      "4  Voluptatem ad rerum assumenda amet pariatur Si...          6   \n",
      "\n",
      "            name_y                                      description_y  \\\n",
      "0   Lucian Ferrell  Beatae tempor eiusmod saepe excepturi sint opt...   \n",
      "1      Dale Ramsey  Fugit sint sapiente molestiae atque autem repr...   \n",
      "2              NaN                                                NaN   \n",
      "3  Charissa Graham  Et quis lorem temporibus reprehenderit est sun...   \n",
      "4   Imogene Nguyen  Duis nisi at voluptas at eum fugiat aliquid pa...   \n",
      "\n",
      "   user_id_y  \n",
      "0        3.0  \n",
      "1        3.0  \n",
      "2        NaN  \n",
      "3        6.0  \n",
      "4        6.0  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Function to fetch data from the API\n",
    "def fetch_data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        return response.json()  # Return JSON data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        return []\n",
    "    except ValueError as e:\n",
    "        print(f\"JSON decode error: {e}\")\n",
    "        return []\n",
    "\n",
    "# API endpoints\n",
    "travels_url = 'http://localhost:8000/list/'\n",
    "checklists_url = 'http://localhost:8000/checklist/list/'\n",
    "\n",
    "# Fetch data from the endpoints\n",
    "travels_data = fetch_data(travels_url)\n",
    "checklists_data = fetch_data(checklists_url)\n",
    "\n",
    "# Convert to Pandas DataFrames\n",
    "travels_df = pd.DataFrame(travels_data)\n",
    "checklists_df = pd.DataFrame(checklists_data)\n",
    "\n",
    "# Forward fill null values\n",
    "travels_df = travels_df.ffill().bfill()  # Fill missing values forward and backward\n",
    "checklists_df = checklists_df.ffill().bfill()\n",
    "\n",
    "# Print DataFrames\n",
    "print(\"Travels DataFrame:\")\n",
    "print(travels_df.head())\n",
    "\n",
    "print(\"\\nChecklists DataFrame:\")\n",
    "print(checklists_df.head())\n",
    "\n",
    "# Merge travels and checklists if they share a relationship (assuming 'id' and 'checklists' are related)\n",
    "merged_df = pd.merge(\n",
    "    travels_df,\n",
    "    checklists_df,\n",
    "    left_on='id',  # Adjust based on your models\n",
    "    right_on='id',  # Adjust based on your models\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Print merged DataFrame\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42663eb-e0d5-475a-98e7-577e1628fcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travels DataFrame:\n",
      "   id            name                                            country  \\\n",
      "0   2   Shelby Daniel  Consectetur qui laboriosam dolore fugiat quaer...   \n",
      "1   3   Jasper Howard  Quaerat sed cupidatat ipsum qui et repellendus...   \n",
      "2   4  Abra Macdonald  Est repellendus Excepteur iure architecto eu p...   \n",
      "3   5     Winter Bush  Eaque quas veniam ea deleniti non in dolores v...   \n",
      "4   7     Lana Conner  Sequi iure quis tempor sunt recusandae Nulla a...   \n",
      "\n",
      "                                                city  \\\n",
      "0  Voluptatem quo aut dolor dolorem excepturi mag...   \n",
      "1  Necessitatibus eligendi minim quibusdam aut ut...   \n",
      "2  Adipisci rerum inventore similique voluptatum ...   \n",
      "3  Illum duis corporis magna sit aut aute in blan...   \n",
      "4                 Quasi at sint ullamco perspiciatis   \n",
      "\n",
      "                                         description  user_id  name_length  \n",
      "0  Fugit beatae voluptate cupidatat unde sed cum ...        2     0.500000  \n",
      "1  Ut id odio cupiditate illo voluptate deleniti ...        2     0.500000  \n",
      "2  Nihil officiis proident qui quis laboris quia ...        3     1.333333  \n",
      "3  In dolor voluptate cumque omnis delectus eos e...        3    -1.166667  \n",
      "4  Voluptatem ad rerum assumenda amet pariatur Si...        6    -1.166667  \n",
      "\n",
      "Checklists DataFrame:\n",
      "   id             name                                        description  \\\n",
      "0   1  Ashely Cantrell  Vero irure fugiat est fugit laudantium iste ve...   \n",
      "1   2   Lucian Ferrell  Beatae tempor eiusmod saepe excepturi sint opt...   \n",
      "2   3      Dale Ramsey  Fugit sint sapiente molestiae atque autem repr...   \n",
      "3   5  Charissa Graham  Et quis lorem temporibus reprehenderit est sun...   \n",
      "4   6    Scott Schultz  Quibusdam omnis fuga Ut quod mollitia anim in ...   \n",
      "\n",
      "   user_id  description_length  \n",
      "0        2            0.705128  \n",
      "1        3            1.000000  \n",
      "2        3            0.397436  \n",
      "3        6            0.320513  \n",
      "4        6            0.525641  \n",
      "\n",
      "Travels DataFrame exported to output_csvs/travels.csv\n",
      "Checklists DataFrame exported to output_csvs/checklists.csv\n",
      "\n",
      "Merged DataFrame:\n",
      "   id     name_travel                                            country  \\\n",
      "0   2   Shelby Daniel  Consectetur qui laboriosam dolore fugiat quaer...   \n",
      "1   3   Jasper Howard  Quaerat sed cupidatat ipsum qui et repellendus...   \n",
      "2   4  Abra Macdonald  Est repellendus Excepteur iure architecto eu p...   \n",
      "3   5     Winter Bush  Eaque quas veniam ea deleniti non in dolores v...   \n",
      "4   7     Lana Conner  Sequi iure quis tempor sunt recusandae Nulla a...   \n",
      "\n",
      "                                                city  \\\n",
      "0  Voluptatem quo aut dolor dolorem excepturi mag...   \n",
      "1  Necessitatibus eligendi minim quibusdam aut ut...   \n",
      "2  Adipisci rerum inventore similique voluptatum ...   \n",
      "3  Illum duis corporis magna sit aut aute in blan...   \n",
      "4                 Quasi at sint ullamco perspiciatis   \n",
      "\n",
      "                                  description_travel  user_id_travel  \\\n",
      "0  Fugit beatae voluptate cupidatat unde sed cum ...               2   \n",
      "1  Ut id odio cupiditate illo voluptate deleniti ...               2   \n",
      "2  Nihil officiis proident qui quis laboris quia ...               3   \n",
      "3  In dolor voluptate cumque omnis delectus eos e...               3   \n",
      "4  Voluptatem ad rerum assumenda amet pariatur Si...               6   \n",
      "\n",
      "   name_length   name_checklist  \\\n",
      "0     0.500000   Lucian Ferrell   \n",
      "1     0.500000      Dale Ramsey   \n",
      "2     1.333333              NaN   \n",
      "3    -1.166667  Charissa Graham   \n",
      "4    -1.166667   Imogene Nguyen   \n",
      "\n",
      "                               description_checklist  user_id_checklist  \\\n",
      "0  Beatae tempor eiusmod saepe excepturi sint opt...                3.0   \n",
      "1  Fugit sint sapiente molestiae atque autem repr...                3.0   \n",
      "2                                                NaN                NaN   \n",
      "3  Et quis lorem temporibus reprehenderit est sun...                6.0   \n",
      "4  Duis nisi at voluptas at eum fugiat aliquid pa...                6.0   \n",
      "\n",
      "   description_length  \n",
      "0            1.578004  \n",
      "1           -0.088652  \n",
      "2                 NaN  \n",
      "3           -0.301417  \n",
      "4           -1.187936  \n",
      "\n",
      "Merged DataFrame exported to output_csvs/merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Function to fetch data from the API\n",
    "\n",
    "def fetch_data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  \n",
    "        return response.json() \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        return []\n",
    "    except ValueError as e:\n",
    "        print(f\"JSON decode error: {e}\")\n",
    "        return []\n",
    "\n",
    "# API endpoints\n",
    "travels_url = 'http://localhost:8000/list/'\n",
    "checklists_url = 'http://localhost:8000/checklist/list/'\n",
    "\n",
    "# Fetch data from the endpoints\n",
    "\n",
    "travels_data = fetch_data(travels_url)\n",
    "checklists_data = fetch_data(checklists_url)\n",
    "\n",
    "# Convert to Pandas DataFrames\n",
    "\n",
    "travels_df = pd.DataFrame(travels_data)\n",
    "checklists_df = pd.DataFrame(checklists_data)\n",
    "\n",
    "# Handle missing values by forward and backward filling\n",
    "\n",
    "travels_df = travels_df.ffill().bfill()\n",
    "checklists_df = checklists_df.ffill().bfill()\n",
    "\n",
    "# Data Cleaning: Removing duplicates\n",
    "\n",
    "travels_df = travels_df.drop_duplicates()\n",
    "checklists_df = checklists_df.drop_duplicates()\n",
    "\n",
    "# Feature Engineering: Add derived features\n",
    "travels_df['name_length'] = travels_df['name'].apply(len)\n",
    "checklists_df['description_length'] = checklists_df['description'].apply(len)\n",
    "\n",
    "# Standardization: Scale numeric features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['name_length']  # Add other numeric columns as needed\n",
    "travels_df[numeric_features] = scaler.fit_transform(travels_df[numeric_features])\n",
    "\n",
    "# Normalization: Scale numeric features to a range [0, 1] using MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "checklist_numeric_features = ['description_length']  # Add other numeric columns as needed\n",
    "checklists_df[checklist_numeric_features] = normalizer.fit_transform(checklists_df[checklist_numeric_features])\n",
    "\n",
    "# Print DataFrames\n",
    "print(\"Travels DataFrame:\")\n",
    "print(travels_df.head())\n",
    "\n",
    "print(\"\\nChecklists DataFrame:\")\n",
    "print(checklists_df.head())\n",
    "\n",
    "# Export individual DataFrames to CSV files\n",
    "output_dir = \"output_csvs\"\n",
    "os.makedirs(output_dir, exist_ok=True) \n",
    "\n",
    "travels_csv_path = os.path.join(output_dir, \"travels.csv\")\n",
    "checklists_csv_path = os.path.join(output_dir, \"checklists.csv\")\n",
    "\n",
    "travels_df.to_csv(travels_csv_path, index=False)\n",
    "checklists_df.to_csv(checklists_csv_path, index=False)\n",
    "\n",
    "print(f\"\\nTravels DataFrame exported to {travels_csv_path}\")\n",
    "print(f\"Checklists DataFrame exported to {checklists_csv_path}\")\n",
    "\n",
    "# Merge travels and checklists on 'id' (assuming they share a relationship)\n",
    "merged_df = pd.merge(\n",
    "    travels_df,\n",
    "    checklists_df,\n",
    "    left_on='id',  \n",
    "    right_on='id',\n",
    "    how='left',\n",
    "    suffixes=('_travel', '_checklist')\n",
    ")\n",
    "\n",
    "# Scaling and Normalizing merged data\n",
    "numeric_columns = ['name_length', 'description_length']  \n",
    "merged_df[numeric_columns] = scaler.fit_transform(merged_df[numeric_columns])\n",
    "\n",
    "# Print and export the merged DataFrame\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "merged_csv_path = os.path.join(output_dir, \"merged_data.csv\")\n",
    "merged_df.to_csv(merged_csv_path, index=False)\n",
    "\n",
    "print(f\"\\nMerged DataFrame exported to {merged_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc0eac-4a8d-4606-9ccb-fb5aba5339c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
