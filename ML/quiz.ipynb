{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4677043-dd31-471e-9f38-a8380a3f8543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travels DataFrame Description:\n",
      "                   id           name  \\\n",
      "count   500000.000000         500000   \n",
      "unique            NaN              5   \n",
      "top               NaN  Shelby Daniel   \n",
      "freq              NaN         100000   \n",
      "mean         4.200000            NaN   \n",
      "std          1.720467            NaN   \n",
      "min          2.000000            NaN   \n",
      "25%          3.000000            NaN   \n",
      "50%          4.000000            NaN   \n",
      "75%          5.000000            NaN   \n",
      "max          7.000000            NaN   \n",
      "\n",
      "                                                  country  \\\n",
      "count                                              500000   \n",
      "unique                                                  5   \n",
      "top     Consectetur qui laboriosam dolore fugiat quaer...   \n",
      "freq                                               100000   \n",
      "mean                                                  NaN   \n",
      "std                                                   NaN   \n",
      "min                                                   NaN   \n",
      "25%                                                   NaN   \n",
      "50%                                                   NaN   \n",
      "75%                                                   NaN   \n",
      "max                                                   NaN   \n",
      "\n",
      "                                                     city  \\\n",
      "count                                              500000   \n",
      "unique                                                  5   \n",
      "top     Voluptatem quo aut dolor dolorem excepturi mag...   \n",
      "freq                                               100000   \n",
      "mean                                                  NaN   \n",
      "std                                                   NaN   \n",
      "min                                                   NaN   \n",
      "25%                                                   NaN   \n",
      "50%                                                   NaN   \n",
      "75%                                                   NaN   \n",
      "max                                                   NaN   \n",
      "\n",
      "                                              description        user_id  \n",
      "count                                              500000  500000.000000  \n",
      "unique                                                  5            NaN  \n",
      "top     Fugit beatae voluptate cupidatat unde sed cum ...            NaN  \n",
      "freq                                               100000            NaN  \n",
      "mean                                                  NaN       3.200000  \n",
      "std                                                   NaN       1.469695  \n",
      "min                                                   NaN       2.000000  \n",
      "25%                                                   NaN       2.000000  \n",
      "50%                                                   NaN       3.000000  \n",
      "75%                                                   NaN       3.000000  \n",
      "max                                                   NaN       6.000000  \n",
      "\n",
      "Checklists DataFrame Description:\n",
      "              id             name  \\\n",
      "count   7.000000                7   \n",
      "unique       NaN                7   \n",
      "top          NaN  Ashely Cantrell   \n",
      "freq         NaN                1   \n",
      "mean    4.571429              NaN   \n",
      "std     2.636737              NaN   \n",
      "min     1.000000              NaN   \n",
      "25%     2.500000              NaN   \n",
      "50%     5.000000              NaN   \n",
      "75%     6.500000              NaN   \n",
      "max     8.000000              NaN   \n",
      "\n",
      "                                              description   user_id  \n",
      "count                                                   7  7.000000  \n",
      "unique                                                  7       NaN  \n",
      "top     Vero irure fugiat est fugit laudantium iste ve...       NaN  \n",
      "freq                                                    1       NaN  \n",
      "mean                                                  NaN  4.571429  \n",
      "std                                                   NaN  1.812654  \n",
      "min                                                   NaN  2.000000  \n",
      "25%                                                   NaN  3.000000  \n",
      "50%                                                   NaN  6.000000  \n",
      "75%                                                   NaN  6.000000  \n",
      "max                                                   NaN  6.000000  \n",
      "\n",
      "Null Values in Travels DataFrame:\n",
      "id             0\n",
      "name           0\n",
      "country        0\n",
      "city           0\n",
      "description    0\n",
      "user_id        0\n",
      "dtype: int64\n",
      "\n",
      "Null Values in Checklists DataFrame:\n",
      "id             0\n",
      "name           0\n",
      "description    0\n",
      "user_id        0\n",
      "dtype: int64\n",
      "\n",
      "Updated Travels DataFrame:\n",
      "    id            name                                            country  \\\n",
      "0  0.0   shelby daniel  Consectetur qui laboriosam dolore fugiat quaer...   \n",
      "1  0.2   jasper howard  Quaerat sed cupidatat ipsum qui et repellendus...   \n",
      "2  0.4  abra macdonald  Est repellendus Excepteur iure architecto eu p...   \n",
      "3  0.6     winter bush  Eaque quas veniam ea deleniti non in dolores v...   \n",
      "4  1.0     lana conner  Sequi iure quis tempor sunt recusandae Nulla a...   \n",
      "\n",
      "                                                city  \\\n",
      "0  Voluptatem quo aut dolor dolorem excepturi mag...   \n",
      "1  Necessitatibus eligendi minim quibusdam aut ut...   \n",
      "2  Adipisci rerum inventore similique voluptatum ...   \n",
      "3  Illum duis corporis magna sit aut aute in blan...   \n",
      "4                 Quasi at sint ullamco perspiciatis   \n",
      "\n",
      "                                         description  user_id  \\\n",
      "0  Fugit beatae voluptate cupidatat unde sed cum ...     0.00   \n",
      "1  Ut id odio cupiditate illo voluptate deleniti ...     0.00   \n",
      "2  Nihil officiis proident qui quis laboris quia ...     0.25   \n",
      "3  In dolor voluptate cumque omnis delectus eos e...     0.25   \n",
      "4  Voluptatem ad rerum assumenda amet pariatur Si...     1.00   \n",
      "\n",
      "                                       full_location  \n",
      "0  Voluptatem quo aut dolor dolorem excepturi mag...  \n",
      "1  Necessitatibus eligendi minim quibusdam aut ut...  \n",
      "2  Adipisci rerum inventore similique voluptatum ...  \n",
      "3  Illum duis corporis magna sit aut aute in blan...  \n",
      "4  Quasi at sint ullamco perspiciatis, Sequi iure...  \n",
      "\n",
      "Updated Checklists DataFrame:\n",
      "    id             name                                        description  \\\n",
      "0  1.0  ashely cantrell  Vero irure fugiat est fugit laudantium iste ve...   \n",
      "1  2.0   lucian ferrell  Beatae tempor eiusmod saepe excepturi sint opt...   \n",
      "2  3.0      dale ramsey  Fugit sint sapiente molestiae atque autem repr...   \n",
      "3  5.0  charissa graham  Et quis lorem temporibus reprehenderit est sun...   \n",
      "4  6.0    scott schultz  Quibusdam omnis fuga Ut quod mollitia anim in ...   \n",
      "\n",
      "   user_id  \n",
      "0        2  \n",
      "1        3  \n",
      "2        3  \n",
      "3        6  \n",
      "4        6  \n",
      "\n",
      "Travels DataFrame exported to output_csvsquiz/travels.csv\n",
      "Checklists DataFrame exported to output_csvsquiz/checklists.csv\n",
      "\n",
      "Merged DataFrame:\n",
      "    id     name_travel                                            country  \\\n",
      "0  0.0   shelby daniel  Consectetur qui laboriosam dolore fugiat quaer...   \n",
      "1  0.2   jasper howard  Quaerat sed cupidatat ipsum qui et repellendus...   \n",
      "2  0.4  abra macdonald  Est repellendus Excepteur iure architecto eu p...   \n",
      "3  0.6     winter bush  Eaque quas veniam ea deleniti non in dolores v...   \n",
      "4  1.0     lana conner  Sequi iure quis tempor sunt recusandae Nulla a...   \n",
      "\n",
      "                                                city  \\\n",
      "0  Voluptatem quo aut dolor dolorem excepturi mag...   \n",
      "1  Necessitatibus eligendi minim quibusdam aut ut...   \n",
      "2  Adipisci rerum inventore similique voluptatum ...   \n",
      "3  Illum duis corporis magna sit aut aute in blan...   \n",
      "4                 Quasi at sint ullamco perspiciatis   \n",
      "\n",
      "                                  description_travel  user_id_travel  \\\n",
      "0  Fugit beatae voluptate cupidatat unde sed cum ...            0.00   \n",
      "1  Ut id odio cupiditate illo voluptate deleniti ...            0.00   \n",
      "2  Nihil officiis proident qui quis laboris quia ...            0.25   \n",
      "3  In dolor voluptate cumque omnis delectus eos e...            0.25   \n",
      "4  Voluptatem ad rerum assumenda amet pariatur Si...            1.00   \n",
      "\n",
      "                                       full_location   name_checklist  \\\n",
      "0  Voluptatem quo aut dolor dolorem excepturi mag...              NaN   \n",
      "1  Necessitatibus eligendi minim quibusdam aut ut...              NaN   \n",
      "2  Adipisci rerum inventore similique voluptatum ...              NaN   \n",
      "3  Illum duis corporis magna sit aut aute in blan...              NaN   \n",
      "4  Quasi at sint ullamco perspiciatis, Sequi iure...  ashely cantrell   \n",
      "\n",
      "                               description_checklist  user_id_checklist  \n",
      "0                                                NaN                NaN  \n",
      "1                                                NaN                NaN  \n",
      "2                                                NaN                NaN  \n",
      "3                                                NaN                NaN  \n",
      "4  Vero irure fugiat est fugit laudantium iste ve...                2.0  \n",
      "\n",
      "Merged DataFrame exported to output_csvsquiz/merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Function to fetch data from the API\n",
    "def fetch_data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        return response.json()  # Return JSON data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        return []\n",
    "    except ValueError as e:\n",
    "        print(f\"JSON decode error: {e}\")\n",
    "        return []\n",
    "\n",
    "# API endpoints\n",
    "travels_url = 'http://localhost:8000/list/'\n",
    "checklists_url = 'http://localhost:8000/checklist/list/'\n",
    "\n",
    "# Fetch data from the endpoints\n",
    "travels_data = fetch_data(travels_url)\n",
    "checklists_data = fetch_data(checklists_url)\n",
    "\n",
    "# Convert to Pandas DataFrames\n",
    "travels_df = pd.DataFrame(travels_data)\n",
    "checklists_df = pd.DataFrame(checklists_data)\n",
    "\n",
    "# Ensure IDs in both DataFrames are of the same type\n",
    "if 'id' in travels_df.columns and 'id' in checklists_df.columns:\n",
    "    travels_df['id'] = travels_df['id'].astype(float)\n",
    "    checklists_df['id'] = checklists_df['id'].astype(float)\n",
    "\n",
    "# Task 1: Return 500,000 rows in your dataset\n",
    "if len(travels_df) < 500000:\n",
    "    travels_df = pd.concat([travels_df] * (500000 // len(travels_df) + 1), ignore_index=True)[:500000]\n",
    "\n",
    "# Task 2: Describe your dataset\n",
    "print(\"Travels DataFrame Description:\")\n",
    "print(travels_df.describe(include='all'))\n",
    "\n",
    "print(\"\\nChecklists DataFrame Description:\")\n",
    "print(checklists_df.describe(include='all'))\n",
    "\n",
    "# Task 3: Check and remove null values in your dataset\n",
    "\n",
    "# Check for null values\n",
    "print(\"\\nNull Values in Travels DataFrame:\")\n",
    "print(travels_df.isnull().sum())\n",
    "\n",
    "print(\"\\nNull Values in Checklists DataFrame:\")\n",
    "print(checklists_df.isnull().sum())\n",
    "\n",
    "# Remove rows with null values\n",
    "travels_df.dropna(inplace=True)\n",
    "checklists_df.dropna(inplace=True)\n",
    "\n",
    "# Task 4: Perform basic data preprocessing\n",
    "\n",
    "# Standardize text fields to lowercase\n",
    "if 'name' in travels_df.columns:\n",
    "    travels_df['name'] = travels_df['name'].str.lower()\n",
    "\n",
    "if 'name' in checklists_df.columns:\n",
    "    checklists_df['name'] = checklists_df['name'].str.lower()\n",
    "\n",
    "# Normalize numerical columns\n",
    "for col in travels_df.select_dtypes(include=[np.number]).columns:\n",
    "    travels_df[col] = (travels_df[col] - travels_df[col].min()) / (travels_df[col].max() - travels_df[col].min())\n",
    "\n",
    "# Task 5: Create some features in your dataset\n",
    "\n",
    "# Create a new feature combining city and country\n",
    "if 'city' in travels_df.columns and 'country' in travels_df.columns:\n",
    "    travels_df['full_location'] = travels_df['city'] + ', ' + travels_df['country']\n",
    "\n",
    "# Print the updated DataFrame heads\n",
    "print(\"\\nUpdated Travels DataFrame:\")\n",
    "print(travels_df.head())\n",
    "\n",
    "print(\"\\nUpdated Checklists DataFrame:\")\n",
    "print(checklists_df.head())\n",
    "\n",
    "# Export individual DataFrames to CSV files\n",
    "output_dir = \"output_csvsquiz\"\n",
    "os.makedirs(output_dir, exist_ok=True)  \n",
    "\n",
    "travels_csv_path = os.path.join(output_dir, \"travels.csv\")\n",
    "checklists_csv_path = os.path.join(output_dir, \"checklists.csv\")\n",
    "\n",
    "travels_df.to_csv(travels_csv_path, index=False)\n",
    "checklists_df.to_csv(checklists_csv_path, index=False)\n",
    "\n",
    "print(f\"\\nTravels DataFrame exported to {travels_csv_path}\")\n",
    "print(f\"Checklists DataFrame exported to {checklists_csv_path}\")\n",
    "\n",
    "# Merge travels and checklists on 'id'\n",
    "merged_df = pd.merge(\n",
    "    travels_df,\n",
    "    checklists_df,\n",
    "    left_on='id',\n",
    "    right_on='id',\n",
    "    how='left',\n",
    "    suffixes=('_travel', '_checklist')\n",
    ")\n",
    "\n",
    "# Print and export the merged DataFrame\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "merged_csv_path = os.path.join(output_dir, \"merged_data.csv\")\n",
    "merged_df.to_csv(merged_csv_path, index=False)\n",
    "\n",
    "print(f\"\\nMerged DataFrame exported to {merged_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c925f54c-2e46-4e36-891f-ec7176556ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
